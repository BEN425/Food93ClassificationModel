# 環境

#### 環境說明

- Python：3.8.13
- CUDA：cu113
- 大多數套件的版本都在 `requirements.txt`，除了 `torch-scatter` 要另外安裝

#### 前置作業

1. 安裝 pyenv：
    1. `curl -fsSL https://pyenv.run | bash`
    2. 將以下程式碼
        ```bash
        export PYENV_ROOT="$HOME/.pyenv"
        [[ -d $PYENV_ROOT/bin ]] && export PATH="$PYENV_ROOT/bin:$PATH"
        eval "$(pyenv init - bash)"
        eval "$(pyenv virtualenv-init -)"
        ```
        複製到 `$HOME/.bashrc` 最後面，並重新啟動終端使其生效
2. 安裝 bzip2：`sudo apt-get install build-essential zlib1g-dev libffi-dev libssl-dev libbz2-dev libreadline-dev libsqlite3-dev liblzma-dev libncurses-dev tk-dev`
3. 安裝 sqlite3：`sudo apt-get install libsqlite3-dev`

#### 架設環境

1. 安裝 Python 版本：`pyenv install 3.8.13`
2. 設定專案 Python 版本：`pyenv local 3.8.13`
3. 建立虛擬環境：`python -m venv s2c `
4. 進入環境：`source ./s2c/bin/activate`
5. 安裝 Python 套件
    - `pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu113`
    - `pip install torch-scatter -f https://data.pyg.org/whl/torch-1.21.1+cu113.html --no-index`
    - `pip list`
    - `pip check`
    - 若出現 `ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.` 錯誤，將虛擬環境資料夾 `./s2c/pyenv.cfg` 中的 `include-system-site-packages` 設為 true
6. 修改 SAM 檔案，將 `mask_decoder.py`, `sam.py` 複製到 SAM Module 中：
    - `cp ./modeling/mask_decoder.py ./s2c/lib/python3.8/site-packages/segment_anything/modeling/`
    - `cp ./modeling/sam.py ./s2c/lib/python3.8/site-packages/segment_anything/modeling/`
7. 下載 SAM model weights 放到 `./pretrained`：https://github.com/facebookresearch/segment-anything

8. 將資料集放到 `Database` 資料夾, 詳細訊息可以查看章節 **Database**

#### 訓練前準備

1. 啟動環境：`pyenv local 3.8.13`, `source ./s2c/bin/activate`
2. 檢查資料集中是否有問題：`cd utility`, `python check_labels.py`, `python ckech_image.py`
3. 調整 `FoodImageCode/cfg/Setting.yml` 的設定，包含路徑、訓練參數等
4. `cd ../FoodImageCode`
5. 清除 CUDA 記憶體：`nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9`, `nvidia-smi`
6. 開始訓練：`python main.py`
7. 訓練結果會存放在 `FoodImageCode/Results` 中，包含 checkpoints 與 tensorboard logs

# Database

資料夾：Database

圖片格式：**JPG, PNG, WEBP, AVIF**, AVIF 格式需要 `pillow-avif-plugin` 套件

類別：93類, multi-class

包含 _AI Food Database_ 與 _Single Food Database_

若一張圖片是 multi-label, 該圖片會同時出現在不同類別的資料夾中. Example：若 `fruit1.jpg` 同時包含 Apple, Orange 類別, 則會同時出現在 Apple 資料夾與 Orange 資料夾中

### 資料夾結構

總共有 4 層資料夾結構

-   First Level：6 Categories Food (六大類食物) 不包含 _乳品類_ 和 _其他_， Index 為 1, 2, 3, 5, 6
    -   `1_CerealsGrainsTubersAndRoots`：全榖雜糧類
    -   `2_OilFatNutAndSeed`：油脂與堅果種子類
    -   `3_FishMeatAndEgg`：豆魚蛋肉類
    -   `5_Vegetable`：蔬菜類
    -   `6_Fruit`：水果類
-   Second Level：13 Categories，Index 從 A 到 I
    -   `A_CeralsGrainsTubersAndRoots`
    -   `B_FatsAndOils`
    -   `C_Poultry`
    -   `D_Meat`
    -   `E_Seafood`
    -   `F_OtherProteinrichFoods`
    -   `G_Vegetables`
    -   `H_Fruits`
    -   `I_RefreshmentAndSnacks`
-   Third Level：將第二層進行細分，Index 為英文+數字。Example：`A1_RiceAndProducts` 是 `A_CeralsGrainsTubersAndRoots` 的子類別
-   Fourth Level：食物名稱本身，總共有 **93 categories**。Example：`Congee`, `Rice` 是 `A1_RiceAndProducts` 的子類別

### 其他檔案

-   `class.txt`：93 類別食物的 ID 與名稱
-   `class_freq.txt`：每個食物類別的比例
-   `class_entropy.txt`：每個食物類別的 entropy (self-information)
-   `FoodSeg_cate_mapping.csv`：FoodSeg103 類別名稱對應到 93 食物類別
-   `id_mapping.csv`：FoodSeg103 類別 ID 對應到 93 食物類別 ID
-   `class_chinese.txt`：食物類別的中文名稱

# Code

資料夾：FoodImageCode

### 資料夾結構

-   `cfg`
    -   `Setting.yml`：Sets various options of training and inference.
-   `model`
    -   `ResNet_modified.py`：Modified ResNet50 model by 嘉宏, re-written in Pytorch by 品潔. The input image size is 3x224x224 (CxWxH). Output size is defined in `Setting.yml`: `MODEL`, `CATEGORY_NUM`.
-   `Results`
    -   `checkpoints`：Model chckpoints generated during training.
    -   `logs`：Training results generated by `SummaryWriter` during training. Can be viewed by Tensorboard.
    -   Both `checkpoints` and `logs` contain subfolders specified in `Setting.yml`.
-   `csv`
    -   CSV files are generated by `make_image_csv.py`. Each csv file contains the path and labels of images, the labels are in multi-hot format.
    -   The path of images are relative to the project path which is specified in `Setting.yml`.
    -   Read **Creating CSV files** section for details.
-   `main.py`：Main program. It reads the datasets from train/valid csv files as well as config file from `./cfg/Setting.yml`, loads the model and starts the training process.
-   `dataset.py`：Defines `FoodDataset` class which inherits Pytorch `Dataset` class. It reads data from a csv file.
-   `training_loop.py`：Defines `Trainer` class for the training process.
-   `metrics.py`：Defines metrics such as accuracy, f1 score and valid set evaluation
-   `loss.py`：Defines loss functions
-   `cfgparser.py`：Defines `CfgParser` class to read yml file.
-   `make_image_csv.py`：Seperates the food images into training, test and validation sets, and stores image paths and labels in csv files.
    -   Read **Creating CSV files** section for details.
-   `test_and_confusion_matrix.py`：Not used.

### Configs

Configs are in `./FoodImageCode/cfg/Setting.yml`. The config file will be parsed by `CfgParser` class in `./FoodImageCode/cfgparser.py`.
The result is `dict` combining `PARSER_SETTING` and `TRAIN_SETTING`.

-   `PARSING_SETTING`
    -   `SEED`
    -   `GPU_ID`
    -   `WORKERS`
    -   `EPOCHS`：Total training epochs
    -   `BATCH_SIZE`：Training batch size
    -   `EVAL_BATCH_SIZE`：Validation batch size
-   `TRAIN_SETTING`
    -   `ROOT`: Project path. The following paths are all relative to `ROOT`
    -   `RESUME`：Resume from the last checkpoint
    -   `CHECKPOINT_PATH`
    -   `TEST_METRICS`: Whether to evaluate on valid set after each epoch.
    -   `DATA_BASE_DIR`：Path of the database used for training
    -   `FOODSEG_DIR`：Path of FoodSeg103 database
    -   `ALL_CSV_DIR`：CSV file containing all images. Only for debug, not used in training and inference.
    -   `TRAIN_CSV_DIR`, `VALID_CSV_DIR`, `TEST_CSV_DIR`：Path of CSV files for training set, validation set and test set. Containing image paths and multi-hot labels.
    -   `FOODSEG_CSV_DIR`
    -   `SAVE_DIR`：Path to save training results, including model checkpoints and tensorboard logs
    -   `SAVE_SUB_NAME`: Subfolder name in `SAVE_DIR/checkpoints` and `SAVE_DIR/logs` to store the current training progress.
    -   `MODEL`
        -   `NAME`
        -   `INCHANNELS`: Input channel numbers. Usually 3 for RGB images.
        -   `OUTCHANNELS`: 64 for ResNet50.
        -   `CATEGORY_NUM`: 93
        -   `LR`：Learning rate
        -   `MOMENTUM`：Momentum for SGD optimizer
        -   `WEIGHT_DECAY`：Weight decay for SGD and Adam optimizer
        -   `CBAM`, `SENET`: Whether to add CBAM and SENet layers
    -   `LOSS`: Specify `ALPHA` and `GAMMA` parameters of focal loss

### Creating CSV files

CSV files are read before training to access the path and labels of all images. CSV files are seperated in training set, test set and validation set. All CSV files are generated by `make_image_csv.py`. The path of CSV files are in `Setting.yml`

In a CSV file, each line represents an image. The first item is path relative to the project path. The rest items are either 0 or 1, corresponding to multi-hot label of the image.

### Loss Functions & Metrics

Loss functions are in `loss.py`. BCE loss and L2 regularization are used in old code. New code uses focal loss.

-   `cal_loss`：Uses BCE loss from Pytorch. Takes sigmoid of model outputs and multi-hot labels as inputs.
-   `cal_focal_loss`：Uses focal loss from Torchvision. This loss function implicitly applies sigmoid to logits. So the inputs do not need to apply sigmoid.
-   `cal_class_focal_loss`：Uses focal loss like `cal_focal_loss`. It allows user to specify alpha for each class and gamma.
-   `cal_l2_regularization`：Calculates L2 regularization.

Metrics are in `metrics.py`, containg precision, recall, F1 score, hamming loss and zero accuracy. Note that micro accuracy does not suitable for multic-label because it includes TN.

-   `cal_tp_fp_fn_tn`: Calculate TP, FP, FN and TN of all classes in a batch.
-   `cal_f1_score_acc`：Calculates F1 score.
-   `cal_ham_zero_acc`：Calculates hamming loss and zero accuracy.
-   `cal_acc`：Calculates accuracy for single-label.
-   `evaluate_valid_dataset`, `evaluate_valid_dataset_class_acc`：Evaluates model on validation set. The function is called after each epoch.

### Training Loop

Defined in `training_loop.py`.

Training results (metrics, loss and model chckpoint) are stored in `Results` folder. The results will update after each training epoch.

# Utility

Folder：utility

Some scripts used for debugging and generating metadata before training.

# Reference

-   <a href=https://arxiv.org/abs/1512.03385>Deep Residual Learning for Image Recognition</a>
-   <a href=https://arxiv.org/abs/1412.6980>Adam: A Method for Stochastic Optimization</a>
-   <a href=https://arxiv.org/abs/1708.02002>Focal Loss for Dense Object Detection</a>
-   <a href=https://arxiv.org/abs/1807.06521>CBAM: Convolutional Block Attention Module</a>
-   <a href=https://arxiv.org/abs/1709.01507>Squeeze-and-Excitation Networks</a>
-   <a href=https://xiongweiwu.github.io/foodseg103.html>A Large-Scale Benchmark for Food Image Segmentation</a>
-   <a href=https://pytorch.org/>PyTorch</a>
