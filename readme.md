# Getting Start 

Environment：
<table>
    <tr>
        <td>Python</td>
        <td>3.7.13</td> </tr>
    <tr>
        <td>Pytorch</td>
        <td>1.12.1</td> </tr>
    <tr>
        <td>Pytorch CUDA</td>
        <td>11.3</td> </tr>
    <tr>
        <td>Torchvision</td>
        <td>0.13.1</td>
    </tr>
    <tr>
        <td>Tensorboard</td>
        <td>2.11.2</td>
    </tr>
    <tr>
        <td>JupyterLab</td>
        <td>3.6.8</td>
    </tr>
    <tr>
        <td>Pillow</td>
        <td>9.4.0</td>
    </tr>
    <tr>
        <td>pillow-avif-plugin</td>
        <td>9.4.0</td>
    </tr>
</table>


1. Put your database in `Database` folder, see **Database** section for detailed file structure.
2. Set up configs in `FoodImageCode/cfg/Setting.yml`, such as file path, hyperparameters, epochs and batch size.
3. Run `FoodImageCode/make_image_csv.py` to generate CSV files of the dataset.
4. Run `FoodImageCode/main.py` to start training.`

# Database

- Folder：Databases
- Name：AI_SingleFood_database_0310
- Categories：93, multi-class
- Image Count：259504
- Image Format：**JPG, PNG, WEBP, AVIF**, need to install `pillow-avif-plugin` to support AVIF format

### Discription
Merged *AI Food Database* and *Single Food Database*.

If an image is multi-class, it will exist repeatedly in multiple folders. For example：if image `fruit.jpg` has both apple and orange classes, it exists both in apple and orange folders.
- *AI Food* has 372095 images and contains both eastern and wester food. Most food images are combinational food. The images are collected from existing datasets.
- *Single Food* has 25647 images. Most food images only have a single food and are Taiwanese food. The images are collected from internet or taken with smartphones.

### File Structure
4 levels of folders
- First Level：6 Categories Food (六大類食物) without 乳品類 and 其他. Index through 1 to 6 without 4 and 7
    - `1_CerealsGrainsTubersAndRoots`：全榖雜糧類
    - `2_OilFatNutAndSeed`：油脂與堅果種子類
    - `3_FishMeatAndEgg`：豆魚蛋肉類
    - `5_Vegetable`：蔬菜類
    - `6_Fruit`：水果類
- Second Level：13 Categories. Index through A to N without M
    - `A_CeralsGrainsTubersAndRoots`
    - `B_FatsAndOils`
    - `C_Poultry`
    - `D_Meat`
    - `E_Seafood`
    - `F_OtherProteinrichFoods`
    - `G_Vegetables`
    - `H_Fruits`
    - `I_RefreshmentAndSnacks`
- Third Level：Further divides second levels. Appends number after the second level indices. For example：`A1_RiceAndProducts` is a subclass of `A_CeralsGrainsTubersAndRoots`
- Fourth Level：Food names under the thrid level. **93 categories** in total. For example：`Congee` and `Rice` are subclasses of `A1_RiceAndProducts`

### Other files
- `class.txt`：IDs of 93 classes used in training and inference
- `FoodSeg_cate_mapping.csv`：Mapping of FoodSeg103 classes to 93 classes. Contains 49 overlapped classes.


# Code

Folder：FoodImageCode

### File Structure

- `cfg`
    - `Setting.yml`：Sets various options of training and inference.
- `model`
    - `ResNet_modified.py`：Modified ResNet50 model by 嘉宏
- `Results`
    - `checkpoints`：Model chckpoints generated during training.
    - `logs`：Training results generated by `SummaryWriter` during training. Can be viewed by Tensorboard
- `csv`
    - CSV files generated by `make_image_csv.py`. Each csv file contains the path and labels of images, the labels are in multi-hot format.
- `main.py`：Main program. It reads the datasets from 3 csv files, config file from `./cfg/Setting.yml` and starts the training process.
- `dataset.py`：Defines `FoodDataset` class which inherits Pytorch `Dataset` class
- `training_loop.py`：Defines `Trainer` class for the training process.
- `metrics.py`：Defines metrics such as accuracy, f1 score and valid set evaluation
- `loss.py`：Defines loss functions
- `cfgparser.py`：Defines `CfgParser` class to read yml file.
- `make_image_csv.py`：Seperates the food images into training, test and validation sets, and stores image paths and labels in csv files.
- `main.ipynb`：Packs all codes in a jupytr notebook for convenient running and testing.
- `test_and_confusion_matrix.py`：Not used.

### Configs

Configs are in `./FoodImageCode/cfg/Setting.yml`. The config file will be parsed by `CfgParser` class in `./FoodImageCode/cfgparser.py`.
The result is `dict` combining `PARSER_SETTING` and `TRAIN_SETTING`.

- `PARSING_SETTING`
    - `SEED`
    - `GPU_ID`
    - `WORKERS`
    - `EPOCHS`：Total training epochs
    - `BATCH_SIZE`：Training batch size
    - `EVAL_BATCH_SIZE`：Validation batch size
- `TRAIN_SETTING`
    - `RESUMEL`：Resume from the last checkpoint
    - `CHECKPOINT_PATH`
    - `TEST_METRICS`
    - `DATA_BASE_DIR`：Path of the database used in training
    - `FOODSEG_DIR`：Path of FoodSeg103 database
    - `ALL_CSV_DIR`：CSV file containing all images. Only for debug, not used in training and inference.
    - `TRAIN_CSV_DIR`, `VALID_CSV_DIR`, `TEST_CSV_DIR`：CSV files for training set, validation set and test set. Containing image paths and multi-hot labels.
    - `FOODSEG_CSV_DIR`
    - `SAVE_DIR`：Path to save training results, including model checkpoints and tensorboard logs
    - `MODEL`
        - `NAME`
        - `INCHANNELS`
        - `OUTCHANNELS`
        - `CATEGORY_NUM`
        - `LR`：Learning rate
        - `MOMENTUM`：Momentum for SGD optimizer
        - `WEIGHT_DECAY`：Weight decay for SGD and Adam optimizer

### Creating CSV files

CSV files are read before training to access the path and labels of all images. CSV files are seperated in training set, test set and validation set. All CSV files are generated by `make_image_csv.py`. The path of CSV files are in `Setting.yml`

In a CSV file, each line represents an image. The first item is path. The rest items are either 0 or 1, corresponding to multi-hot label of the image.

### Loss Functions & Metrics

Loss functions are in `loss.py`. BCE loss and L2 regularization are used in old code. New code uses focal loss.

- `cal_loss`：Uses BCE loss from Pytorch. Takes sigmoid of model outputs and multi-hot labels as inputs.
- `cal_focal_loss`：Uses focal loss from Torchvision. This loss function implicitly applies sigmoid to logits. So the inputs do not need to apply sigmoid.
- `cal_l2_regularization`：Calculates L2 regularization.

Metrics are in `metrics.py`, containg precision, recall, F1 score, hamming loss and zero accuracy. Note that micro accuracy does not suitable for multic-label because it includes TN.

- `cal_f1_score_acc`：Calculates F1 score. Takes sigmoid of model outputs as input.
- `cal_ham_zero_acc`：Calculates hamming loss and zero accuracy. Takes thresholding result after sigmoid of model outputs (to convert the value to either 0 or 1) as input.
- `cal_acc`：Calculates accuracy for single-label. Takes raw model outputs as input.
- `evaluate_valid_dataset`, `evaluate_valid_dataset_new`：Evaluates model on validation set. The function is called after each epoch. The new version uses focal loss, zero accuracy and hamming loss. The original version uses BCE loss and L2 regularization.

### Training Loop

Defined in `training_loop.py`. The original `training_loop` uses BCE loss and L2 regularization. The new version `training_loop_new` uses focal loss, zero accuracy and hamming loss.

After each epoch, the metrics, loss and model chckpoint are stored in `Results` folder.
