'''
loss.py

Defines loss function for training and inference
BCE (Binary Cross Entropy) loss for multilabel classfication
Focal loss for unbalanced dataset
'''

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torchvision.ops.focal_loss import sigmoid_focal_loss
import torch_scatter

### Loss CLS ###

# loss = nn.CrossEntropyLoss()
bce_loss = nn.BCELoss()

def cal_bce_loss(logits: torch.Tensor, label: torch.Tensor) -> torch.Tensor:
    '''
    Calculate BCE loss between `logits` and `label`
    '''
    return bce_loss(logits, label)

def cal_class_focal_loss(
    logits: torch.Tensor,
    label: torch.Tensor,
    class_alpha: torch.Tensor = .25,
    gamma: float = 2,
    mean: bool = True,
) -> torch.Tensor:
    """
    Calculate sigmoid focal loss between `logits` and `label`.
    
    `sigmoid_focal_loss` implicitly applies sigmoid function to logits.

    Arguments :
        `logits` and `label` are both of dimenison `[batch_size, num_classes]`
        `logits` is model output (without sigmoid)
        `label` is multi-hot encoded ground-truth labels
        class_alpha   `Tensor`: Alpha Î± of focal loss for each class. Each value is in range [0, 1]. Default is 0.25
        gamma `float`: Exponent of the modulating factor (1 - p_t) to
                balance easy vs hard examples. Default is 2.
    """
    
    # BCE Loss
    p = torch.sigmoid(logits)
    ce_loss = F.binary_cross_entropy_with_logits(logits, label, reduction="none")
    
    # Gamma
    p_t = p * label + (1 - p) * (1 - label)
    loss = ce_loss * ((1 - p_t) ** gamma)

    # Alpha
    class_alpha = .25 if class_alpha is None else class_alpha
    alpha_t = (1 - class_alpha) * label + class_alpha * (1 - label)
    loss = alpha_t * loss

    return loss.mean() if mean else loss

def cal_l2_regularization(model, beta=1e-4) -> torch.Tensor:
    l2_reg = 0.0
    for name, param in model.named_parameters():
        if "conv" in name and param.requires_grad:
            l2_reg += 0.5 * torch.sum(param ** 2)
    return beta * l2_reg

### Loss SSC ###

def cal_ssc_loss(
    se_map: torch.Tensor,
    feat_map: torch.Tensor,
    target_size: "tuple[int, int]" = None,
    T: float = 1
) -> torch.Tensor :
    '''
    Calculate SSC loss from the segmentation map and feature map
    
    Arguments :
        se_map `Tensor` "[B, 512, 512]": Segmentation map generated by SAM. Can be read from `gen_sam_map.py`
        feat_map `Tensor` "[B, 2048, 14, 14]": Feature map from the convolution layers of the model
        target_size `tuple[int, int]`: The size that feature map were resized. Default is SAM mask size
        T: temperature. Default is 1
    '''
    
    # Resize SAM masks
    if target_size is not None :
        se_map = se_map.float()
        se_map = F.interpolate(se_map.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False)
        se_map = se_map.squeeze(0)
    
    se_map = se_map.long()
    
    _, H, W = se_map.shape

    B, D = feat_map.shape[:2]
    se_map = se_map + 1 # torch_scatter does not use negative index

    # Resize feature map to the size of seg map
    feat_map = F.interpolate(feat_map, size=(H, W), mode='bilinear', align_corners=False)
    feat_map = F.normalize(feat_map, dim=1)
    
    # Unfold H,W. Make seg map and feature map correspond dimensions
    feat_main = feat_map.view(B, D, -1)                                   # (B, D, HW)
    indices = se_map.view(B, 1, -1)                                       # (B, 1, HW)

    # Prototype: Average the feature in the same region of seg map (Region-wise average)
    pt = torch_scatter.scatter_mean(feat_main, indices)                   # (B, D, N)
    pt = F.normalize(pt, dim=1)
    indices = indices.squeeze(1)                                          # (B, HW)
    
    # Calculate SSC loss
    pred_ssc = torch.bmm(pt.permute(0, 2, 1), feat_main)                  # (B, [N,D] * [D,HW]) = (B, N, HW)
    loss_ssc = F.cross_entropy(pred_ssc * T, indices, ignore_index=0)

    # print(f"feat_map: {feat_map.shape}")
    # print(f"feat_main: {feat_main.shape}")
    # print(f"pt: {pt.shape}")
    # print(f"index: {indices.shape}")
    # print(f"pred: {pred_ssc.shape}")
    # print(f"loss: {loss_ssc.shape}")
    
    # se_map = se_map - 1
    if  torch.isnan(loss_ssc):
        print("loss_ssc is NaN!")

    return loss_ssc

### Loss CPM ###

def select_best_sam_mask_by_cam_overlap(
        masks: torch.Tensor,
        cam_region: torch.Tensor,
        target_size: "tuple[int, int]" = (224,224),
        threshold: float = 0.1
) -> "tuple[int, torch.Tensor]" :
    """
    Select the best mask generated by SAM by mIoU
    
    Arguments :
        masks `Tensor` "[1, 3, H, W]"
        cam_region `Tensor` "[H, W]"

    """

    N = masks.shape[0]
    
    # Resize SAM mask to image size
    masks = F.interpolate(
        masks.float(), size=target_size,
        mode='bilinear', align_corners=False
    ) > 0.5 # (N,H,W) BoolTensor

    if masks.dim() == 4 : 
        masks = masks.squeeze(0)
    # print(f"masks: {masks.shape}")

    # Binarize CAM
    cam_bin = cam_region > threshold # (H,W)  Bool

    # Select best SAM mask by mIoU between CAM and SAM mask
    best_idx, best_mask, best_iou = -1, None, 0.0
    for i in range(N):
        inter = (masks[i] & cam_bin).sum().item()
        union = (masks[i] | cam_bin).sum().item()
        iou   = inter / union if union else 0.0
        if iou > best_iou :
            best_iou, best_idx, best_mask = iou, i, masks[i]

    # print(f"best mask: {best_mask.shape}")
    return best_idx, best_mask

def denorm(img):
    mean_img = [0.485, 0.456, 0.406]
    std_img = [0.229, 0.224, 0.225]
    tf_denorm = transforms.Normalize(
        mean = [-m/s for m, s in zip(mean_img, std_img)],
        std =  [1/s for s in std_img]
    )
    return tf_denorm(img)

def calc_cpm_loss(cam_main: torch.Tensor, pgt_sam: torch.Tensor) -> torch.Tensor :
    '''
    Calculate CPM loss from the segmentation map and CAM
    
    Arguments :
        cam_main `Tensor` "[B, CLS+1, H, W]": CAM with additional channel of background
        pgt_sam `Tensor` "[B, H, W]": Pseudo ground-truth label from CAM scores and SAM maps
    '''

    loss_cpm = F.cross_entropy(cam_main, pgt_sam)
    if torch.isnan(loss_cpm):
        print("loss_cpm is NaN!")
        loss_cpm = torch.tensor(0.0, device=cam_main.device)
        
    return loss_cpm

if __name__ == "__main__" :
    a = [
        [1, 2],
        [4, 5]
    ]
    
    for i, j, k in a :
        print(i, j, k)